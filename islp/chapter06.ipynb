{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b064cb7b",
   "metadata": {},
   "source": [
    "# Linear Model Selection and Regularization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb4b8c77",
   "metadata": {},
   "source": [
    "## Initial Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93979cdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reload modules automatically\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb4dac97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Builtin imports\n",
    "import sys\n",
    "import warnings\n",
    "\n",
    "from functools import partial\n",
    "# from typing import Tuple, List, Dict\n",
    "\n",
    "# Data science imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Natsort for natural sorting\n",
    "# from natsort import natsorted\n",
    "\n",
    "# Optimization imports\n",
    "from l0bnb import fit_path\n",
    "\n",
    "# Visualization imports\n",
    "from matplotlib.pyplot import subplots\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# Linear regression from statsmodels\n",
    "from statsmodels.api import OLS\n",
    "\n",
    "# Main scikit-learn imports\n",
    "import sklearn.linear_model as skl\n",
    "import sklearn.model_selection as skm\n",
    "from sklearn.cross_decomposition import PLSRegression\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "# from sklearn.cross_decomposition import PLSRegression\n",
    "# from sklearn.linear_model import LassoCV, Ridge\n",
    "# from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "# from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Introduction to Statistical Learning in Python (ISLP) imports\n",
    "from ISLP import load_data\n",
    "from ISLP.models import ModelSpec as MS\n",
    "from ISLP.models import Stepwise, sklearn_selected, sklearn_selection_path \n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d257188",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add project root to sys.path for module imports\n",
    "if \"/statapp/islp\" not in sys.path:\n",
    "    sys.path.append(\"/statapp/islp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5657bcbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ancillar module imports\n",
    "import ancillar as aux"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c7aef02",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "## Laboratory: Linear Models and Regularization Methods"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3854dc7c",
   "metadata": {},
   "source": [
    "### Subset Selection Methods"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f12e2f75",
   "metadata": {},
   "source": [
    "#### Forward Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9000dd5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "Hitters = load_data(\"Hitters\")\n",
    "\n",
    "print(f\">>> Count missing values in Hitters dataset: {Hitters.isnull().sum().sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6dc37d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "Hitters: pd.DataFrame = Hitters.dropna()\n",
    "\n",
    "# Show it.\n",
    "Hitters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f20a582",
   "metadata": {},
   "outputs": [],
   "source": [
    "def nCp(sigma2, estimator, X, Y):\n",
    "    \"\"\"\n",
    "    Negative Cp statistic.\n",
    "    \"\"\"\n",
    "    \n",
    "    n, p = X.shape\n",
    "    Yhat = estimator.predict(X)\n",
    "    RSS = np.sum((Y - Yhat)**2)\n",
    "    \n",
    "    return -(RSS + 2 * p * sigma2) / n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a09b995a",
   "metadata": {},
   "outputs": [],
   "source": [
    "design = MS(Hitters.columns.drop(\"Salary\")).fit(Hitters)\n",
    "\n",
    "Y: np.array = np.array(Hitters[\"Salary\"])\n",
    "X: pd.DataFrame = design.transform(Hitters)\n",
    "\n",
    "sigma2: float = float(OLS(Y,X).fit().scale)\n",
    "\n",
    "sigma2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50759024",
   "metadata": {},
   "outputs": [],
   "source": [
    "neg_Cp = partial(nCp, sigma2)\n",
    "neg_Cp?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "346c0a62",
   "metadata": {},
   "outputs": [],
   "source": [
    "strategy = Stepwise.first_peak(\n",
    "    model_spec=design,\n",
    "    direction=\"forward\",\n",
    "    max_terms=len(design.terms)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aaa2ed1",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "hitters_MSE = sklearn_selected(OLS, strategy)\n",
    "hitters_MSE.fit(Hitters, Y)\n",
    "hitters_MSE.selected_state_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d0cef6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "hitters_Cp = sklearn_selected(OLS, strategy, scoring=neg_Cp)\n",
    "hitters_Cp.fit(Hitters, Y)\n",
    "hitters_Cp.selected_state_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2646b28d",
   "metadata": {},
   "source": [
    "#### Choosing Among Models Using the Validation Set Approach and Cross-Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7777f6f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "strategy = Stepwise.fixed_steps(\n",
    "    design,\n",
    "    len(design.terms),\n",
    "    direction='forward'\n",
    ")\n",
    "\n",
    "full_path = sklearn_selection_path(OLS, strategy)\n",
    "full_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7421541",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "full_path.fit(Hitters, Y)\n",
    "Yhat_in: np.ndarray = full_path.predict(Hitters)\n",
    "Yhat_in.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66b63803",
   "metadata": {},
   "outputs": [],
   "source": [
    "mse_fig, ax = subplots(figsize=(12, 3))\n",
    "\n",
    "insample_mse: np.ndarray = ((Yhat_in - Y[:, None]) ** 2).mean(0)\n",
    "n_steps: int = insample_mse.shape[0]\n",
    "\n",
    "ax.plot(\n",
    "    np.arange(n_steps),\n",
    "    insample_mse,\n",
    "    marker=\"o\",\n",
    "    color=\"k\",  # color black\n",
    "    label=\"In-sample\"\n",
    ")\n",
    "ax.set_ylabel(\"MSE\", fontsize=20)\n",
    "ax.set_xlabel(\"# steps of forward stepwise\", fontsize=20)\n",
    "ax.set_xticks(np.arange(n_steps))\n",
    "ax.set_xticks(np.arange(n_steps)[::2])\n",
    "ax.legend()\n",
    "ax.grid()\n",
    "ax.set_ylim([50000, 250000]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b43c52d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "K: int = 5\n",
    "kfold = skm.KFold(K, random_state=0, shuffle=True)\n",
    "Yhat_cv: np.ndarray = skm.cross_val_predict (full_path, Hitters, Y, cv=kfold)\n",
    "\n",
    "Yhat_cv.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1097201f",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_mse = []\n",
    "for train_idx, test_idx in kfold.split(Y):\n",
    "\n",
    "    errors = (Yhat_cv[test_idx] - Y[test_idx, None])**2\n",
    "    \n",
    "    # Column means.\n",
    "    cv_mse.append(errors.mean(0))  \n",
    "\n",
    "cv_mse = np.array(cv_mse).T\n",
    "\n",
    "cv_mse.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12f65159",
   "metadata": {},
   "outputs": [],
   "source": [
    "ax.errorbar(\n",
    "    np.arange(n_steps),\n",
    "    cv_mse.mean(axis=1),\n",
    "    cv_mse.std(axis=1) / np.sqrt(K),\n",
    "    label=\"Cross-validated\",\n",
    "    color=\"red\",\n",
    "    marker=\"o\"\n",
    ")\n",
    "\n",
    "ax.set_ylim([50000, 250000])\n",
    "ax.legend()\n",
    "mse_fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60a827b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "validation = skm.ShuffleSplit(\n",
    "    n_splits=1, test_size=0.2, random_state=0\n",
    ")\n",
    "\n",
    "for train_idx, test_idx in validation.split(Y):\n",
    "    \n",
    "    full_path.fit(Hitters.iloc[train_idx], Y[train_idx])\n",
    "    Yhat_val = full_path.predict(Hitters.iloc[test_idx])\n",
    "    errors = (Yhat_val - Y[test_idx, None])**2\n",
    "    \n",
    "    validation_mse = errors.mean(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66913850",
   "metadata": {},
   "outputs": [],
   "source": [
    "ax.plot(\n",
    "    np.arange(n_steps), \n",
    "    validation_mse, \n",
    "    marker=\"o\",\n",
    "    color=\"blue\",\n",
    "    linestyle=\"--\", # color blue, broken line\n",
    "    label=\"Validation\")\n",
    "\n",
    "ax.set_xticks(np.arange(n_steps)[::2])\n",
    "ax.set_ylim([50000, 250000])\n",
    "ax.legend()\n",
    "mse_fig"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f5f0b14",
   "metadata": {},
   "source": [
    "#### Best Subset Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "580213b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "D = design.fit_transform(Hitters)\n",
    "D = D.drop(\"intercept\", axis=1)\n",
    "X = np.asarray(D)\n",
    "\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d69bda64",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# TODO: error in this cell:\n",
    "# AttributeError: `np.Inf` was removed in the NumPy 2.0 release. Use `np.inf` instead.\n",
    "# path = fit_path(X, Y, max_nonzeros=X.shape[1])\n",
    "# path[3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d20ec75d",
   "metadata": {},
   "source": [
    "### Ridge Regression and the Lasso"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d5c36ab",
   "metadata": {},
   "source": [
    "#### Ridge Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef449691",
   "metadata": {},
   "outputs": [],
   "source": [
    "Xs = X - X.mean(axis=0)[None, :]\n",
    "X_scale = X.std(axis=0)\n",
    "Xs = Xs / X_scale[None,:]\n",
    "\n",
    "print(f\">>> Scaled data shape: {Xs.shape}\")\n",
    "\n",
    "lambdas = 10 ** np.linspace(8, -2, 100) / Y.std() \n",
    "soln_array = skl.ElasticNet.path(X=Xs, y=Y, l1_ratio=0., alphas=lambdas)[1]\n",
    "\n",
    "print(f\">>> Number of lambdas: {lambdas.shape[0]}\")\n",
    "print(f\">>> Solution array shape: {soln_array.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5aebeff",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 2.5))\n",
    "plt.plot(lambdas, marker=\"o\")\n",
    "plt.ylabel(\"Lambda\", weight=\"bold\")\n",
    "plt.title(\"Ridge Regression: Lambda Path\", weight=\"bold\")\n",
    "plt.yscale(\"log\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fad1615",
   "metadata": {},
   "outputs": [],
   "source": [
    "soln_path: pd.DataFrame = pd.DataFrame(soln_array.T, columns=D.columns, index=-np.log(lambdas))\n",
    "soln_path.index.name = \"negative log(lambda)\"\n",
    "\n",
    "# Show the solution path.\n",
    "soln_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3ad18d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_fig, ax = subplots(figsize=(9, 6)) \n",
    "soln_path.plot(ax=ax, legend=False, marker=\".\")\n",
    "ax.set_xlabel(\"$-\\log(\\lambda)$\")\n",
    "ax.set_ylabel(\"Standardized coefficients\") \n",
    "\n",
    "# Set legend ouside plot.\n",
    "ax.legend(loc=\"upper left\", bbox_to_anchor=(1, 1))\n",
    "ax.grid(alpha=0.10);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e0e4d5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "soln_path2 = soln_path.copy()\n",
    "soln_path2.index = lambdas\n",
    "soln_path2.index.name = \"lambda\"\n",
    "soln_path2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bde2382",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_fig, ax = subplots(figsize=(9, 6)) \n",
    "soln_path2.plot(ax=ax, legend=False, marker=\".\")\n",
    "ax.set_xlabel(\"$\\\\lambda$\")\n",
    "ax.set_ylabel(\"Standardized coefficients\") \n",
    "\n",
    "# Set legend ouside plot.\n",
    "ax.legend(loc=\"upper left\", bbox_to_anchor=(1, 1))\n",
    "ax.grid(alpha=0.10);\n",
    "ax.set_xscale(\"log\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15173e03",
   "metadata": {},
   "outputs": [],
   "source": [
    "ridge = skl.ElasticNet(alpha=lambdas[59], l1_ratio=0)\n",
    "scaler = StandardScaler(with_mean=True, with_std=True)\n",
    "\n",
    "pipe = Pipeline(\n",
    "    steps=[\n",
    "        (\"scaler\", scaler), \n",
    "        (\"ridge\", ridge)\n",
    "    ]\n",
    ") \n",
    "\n",
    "pipe.fit(X, Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07e4aca0",
   "metadata": {},
   "source": [
    "#### Estimating Test Error of Ridge Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3200b64e",
   "metadata": {},
   "outputs": [],
   "source": [
    "validation = skm.ShuffleSplit(\n",
    "    n_splits=1, \n",
    "    test_size=0.5,\n",
    "    random_state=0\n",
    ")\n",
    "\n",
    "ridge.alpha = 0.01\n",
    "\n",
    "results = skm.cross_validate(\n",
    "    estimator=ridge,\n",
    "    X=X,\n",
    "    y=Y,\n",
    "    scoring=\"neg_mean_squared_error\",\n",
    "    cv=validation,\n",
    ")\n",
    "\n",
    "# Show it.\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05cbe67c",
   "metadata": {},
   "outputs": [],
   "source": [
    "ridge.alpha = 1e10\n",
    "\n",
    "results = skm.cross_validate(\n",
    "    estimator=ridge,\n",
    "    X=X,\n",
    "    y=Y,\n",
    "    scoring=\"neg_mean_squared_error\",\n",
    "    cv=validation,\n",
    ")\n",
    "\n",
    "# Show it.\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d455b215",
   "metadata": {},
   "outputs": [],
   "source": [
    "for train_idx, test_idx in validation.split(X, Y):\n",
    "    prediction = Y[train_idx].mean()\n",
    "    print(\">>> Mean of Y in training set: {prediction}\", )\n",
    "\n",
    "# Calculate the MSE of this prediction in test split.\n",
    "mse = ((prediction - Y[test_idx])**2).mean()\n",
    "print(f\">>> MSE of this prediction: {mse}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9458ff9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Percentual error.\n",
    "np.abs((- results[\"test_score\"] - mse) / (- results[\"test_score\"]) * 100)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63121472",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    \"ridge__alpha\": lambdas\n",
    "}\n",
    "\n",
    "grid = skm.GridSearchCV(\n",
    "    estimator=pipe,\n",
    "    param_grid=param_grid,\n",
    "    scoring=\"neg_mean_squared_error\",\n",
    "    cv=validation,\n",
    ")\n",
    "\n",
    "grid.fit(X, Y)\n",
    "\n",
    "# Show best parameters.\n",
    "grid.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5f64a7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show best estimator.\n",
    "grid.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f58f2da",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "grid = skm.GridSearchCV(pipe, param_grid, cv=kfold, scoring='neg_mean_squared_error')\n",
    "\n",
    "grid.fit(X, Y) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23d4708c",
   "metadata": {},
   "outputs": [],
   "source": [
    "ridge_fig, ax = subplots(figsize=(7, 4)) \n",
    "\n",
    "ax.errorbar(\n",
    "    lambdas,\n",
    "    -grid.cv_results_[\"mean_test_score\"],\n",
    "    yerr=grid.cv_results_[\"std_test_score\"] / np.sqrt(K)\n",
    ")\n",
    "\n",
    "ax.set_xscale(\"log\")\n",
    "ax.set_xlabel(\"$\\lambda$\", fontsize=10)\n",
    "ax.set_ylabel(\"Cross-validated MSE\", fontsize=10);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b17d7ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "ridge_fig, ax = subplots(figsize=(7, 4)) \n",
    "\n",
    "ax.errorbar(\n",
    "    -np.log(lambdas),\n",
    "    -grid.cv_results_[\"mean_test_score\"],\n",
    "    yerr=grid.cv_results_[\"std_test_score\"] / np.sqrt(K)\n",
    ")\n",
    "\n",
    "ax.set_ylim([50000,250000])\n",
    "ax.set_xlabel(\"$-\\log(\\lambda)$\", fontsize=10)\n",
    "ax.set_ylabel(\"Cross-validated MSE\", fontsize=10);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c978e62",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_r2 = skm.GridSearchCV(pipe, param_grid, cv=kfold, scoring=\"r2\")\n",
    "\n",
    "grid_r2.fit(X, Y);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bc8608a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ridge_fig, ax = subplots(figsize=(7, 4)) \n",
    "\n",
    "ax.errorbar(\n",
    "    -np.log(lambdas),\n",
    "    grid_r2.cv_results_[\"mean_test_score\"], \n",
    "    yerr=grid_r2.cv_results_[\"std_test_score\"] / np.sqrt(K)\n",
    ")\n",
    "\n",
    "ax.set_xlabel(\"$-\\log(\\lambda)$\", fontsize=10)\n",
    "ax.set_ylabel(\"Cross-validated $R^2$\", fontsize=10);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a86139d3",
   "metadata": {},
   "source": [
    "#### Fast Cross-Validation for Solution Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31270380",
   "metadata": {},
   "outputs": [],
   "source": [
    "ridgeCV = skl.ElasticNetCV(\n",
    "    alphas=lambdas, \n",
    "    l1_ratio=0,\n",
    "    cv=kfold\n",
    ")\n",
    "\n",
    "pipeCV = Pipeline(steps=[\n",
    "    (\"scaler\", scaler),\n",
    "    (\"ridge\", ridgeCV)\n",
    "])\n",
    "\n",
    "pipeCV.fit(X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuned_ridge = pipeCV.named_steps[\"ridge\"]\n",
    "\n",
    "ridgeCV_fig, ax = subplots(figsize=(7, 4))\n",
    "\n",
    "ax.errorbar(\n",
    "    -np.log(lambdas),\n",
    "    tuned_ridge.mse_path_.mean(1),\n",
    "    yerr=tuned_ridge.mse_path_.std(1) / np.sqrt(K)\n",
    ")\n",
    "\n",
    "ax.axvline(-np.log(tuned_ridge.alpha_), c=\"k\", ls=\"--\")\n",
    "ax.set_ylim([50000, 250000])\n",
    "ax.set_xlabel(\"$-\\log(\\lambda)$\", fontsize=10)\n",
    "ax.set_ylabel(\"Cross-validated MSE\", fontsize=10);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.min(tuned_ridge.mse_path_.mean(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c9b87ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "tuned_ridge.coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccdd8a96",
   "metadata": {},
   "source": [
    "#### Evaluating Test Error of Cross-Validated Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1086132",
   "metadata": {},
   "outputs": [],
   "source": [
    "outer_valid = skm.ShuffleSplit(n_splits=1, test_size=0.25, random_state=1)\n",
    "\n",
    "inner_cv = skm.KFold(n_splits=5, shuffle=True, random_state=2)\n",
    "ridgeCV = skl.ElasticNetCV(alphas=lambdas, l1_ratio=0, cv=inner_cv)\n",
    "\n",
    "pipeCV = Pipeline(steps=[\n",
    "    (\"scaler\", scaler), \n",
    "    (\"ridge\", ridgeCV)\n",
    "]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42fbb364",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = skm.cross_validate(pipeCV, X, Y, cv=outer_valid, scoring='neg_mean_squared_error')\n",
    "\n",
    "-results['test_score'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62b065eb",
   "metadata": {},
   "source": [
    "#### The Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb138869",
   "metadata": {},
   "outputs": [],
   "source": [
    "lassoCV = skl.ElasticNetCV(n_alphas=100, l1_ratio=1, cv=kfold)\n",
    "\n",
    "pipeCV = Pipeline(steps=[\n",
    "    (\"scaler\", scaler), \n",
    "    (\"lasso\", lassoCV)\n",
    "])\n",
    "\n",
    "pipeCV.fit(X, Y)\n",
    "tuned_lasso = pipeCV.named_steps[\"lasso\"]\n",
    "\n",
    "tuned_lasso.alpha_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f24d9306",
   "metadata": {},
   "outputs": [],
   "source": [
    "lambdas, soln_array = skl.Lasso.path(Xs, Y, l1_ratio=1, n_alphas=100)[:2]\n",
    "soln_path = pd.DataFrame(soln_array.T, columns=D.columns, index=-np.log(lambdas))\n",
    "\n",
    "soln_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c12eaa08",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_fig, ax = subplots(figsize=(9, 5))\n",
    "\n",
    "soln_path.plot(ax=ax, marker='.', legend=False)\n",
    "\n",
    "ax.legend(loc=\"upper left\", bbox_to_anchor=(1, 1))\n",
    "ax.set_xlabel(\"$-\\log(\\lambda)$\", fontsize=10)\n",
    "ax.set_ylabel(\"Standardized coefficiients\", fontsize=10);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lassoCV_fig, ax = subplots(figsize=(7, 4))\n",
    "\n",
    "ax.errorbar(\n",
    "    -np.log(tuned_lasso.alphas_),\n",
    "    tuned_lasso.mse_path_.mean(1),\n",
    "    yerr=tuned_lasso.mse_path_.std(1) / np.sqrt(K)\n",
    ")\n",
    "\n",
    "ax.axvline(-np.log(tuned_lasso.alpha_), c=\"k\", ls=\"--\")\n",
    "ax.set_ylim([50000,250000])\n",
    "ax.set_xlabel(\"$-\\log(\\lambda)$\", fontsize=10)\n",
    "ax.set_ylabel(\"Cross-validated MSE\", fontsize=10);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e72ff6d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "tuned_lasso.coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dd4a8c9",
   "metadata": {},
   "source": [
    "### PCR and PLS Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db1e5a1a",
   "metadata": {},
   "source": [
    "#### Principal Components Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "729cbaf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=2)\n",
    "linreg = skl.LinearRegression()\n",
    "\n",
    "pipe = Pipeline([(\"pca\", pca), (\"linreg\", linreg)])\n",
    "pipe.fit(X, Y)\n",
    "\n",
    "pipe.named_steps[\"linreg\"].coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = Pipeline([(\"scaler\", scaler), (\"pca\", pca), (\"linreg\", linreg)])\n",
    "\n",
    "pipe.fit(X, Y)\n",
    "\n",
    "pipe.named_steps[\"linreg\"].coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\"pca__n_components\": range(1, 20)}\n",
    "\n",
    "grid = skm.GridSearchCV(\n",
    "    estimator=pipe,\n",
    "    param_grid=param_grid,\n",
    "    cv=kfold,\n",
    "    scoring=\"neg_mean_squared_error\"\n",
    ")\n",
    "\n",
    "grid.fit(X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "608bca0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pcr_fig, ax = subplots(figsize=(7, 4))\n",
    "n_comp = param_grid[\"pca__n_components\"]\n",
    "\n",
    "ax.errorbar(\n",
    "    n_comp,\n",
    "    -grid.cv_results_[\"mean_test_score\"],\n",
    "    grid.cv_results_[\"std_test_score\"] / np.sqrt(K)\n",
    ")\n",
    "\n",
    "ax.set_ylabel(\"Cross-validated MSE\", fontsize=10)\n",
    "ax.set_xlabel(\"# principal components\", fontsize=10)\n",
    "ax.set_xticks(n_comp[::2])\n",
    "ax.set_ylim([50000,250000]);\n",
    "\n",
    "print(f\">>> Best number of principal components: {grid.best_params_['pca__n_components']}\")\n",
    "\n",
    "# Plot vertical orange dashed line at best number of components\n",
    "ax.axvline(grid.best_params_['pca__n_components'], color='orange', linestyle='--');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xn: np.ndarray = np.zeros((X.shape[0], 1))\n",
    "\n",
    "cv_null = skm.cross_validate(\n",
    "    estimator=linreg,\n",
    "    X=Xn,\n",
    "    y=Y,\n",
    "    cv=kfold,\n",
    "    scoring=\"neg_mean_squared_error\"\n",
    ")\n",
    "\n",
    "float(-cv_null[\"test_score\"].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ef5d7f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe.named_steps[\"pca\"]. explained_variance_ratio_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35cc58c0",
   "metadata": {},
   "source": [
    "#### Partial Least Squares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22dee1f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "pls = PLSRegression(n_components=2, scale=True)\n",
    "\n",
    "pls.fit(X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fbd9c39",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\"n_components\":range(1, 20)}\n",
    "\n",
    "grid = skm.GridSearchCV(\n",
    "    estimator=pls,\n",
    "    param_grid=param_grid,\n",
    "    cv=kfold,\n",
    "    scoring=\"neg_mean_squared_error\"\n",
    ")\n",
    "\n",
    "grid.fit(X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2774edfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "pls_fig, ax = subplots(figsize=(7, 4))\n",
    "\n",
    "n_comp = param_grid[\"n_components\"]\n",
    "\n",
    "ax.errorbar(\n",
    "    n_comp,\n",
    "    -grid.cv_results_[\"mean_test_score\"],\n",
    "    grid.cv_results_[\"std_test_score\"] / np.sqrt(K)\n",
    ")\n",
    "\n",
    "ax.set_ylabel(\"Cross-validated MSE\", fontsize=10)\n",
    "ax.set_xlabel(\"# principal components\", fontsize=10)\n",
    "ax.set_xticks(n_comp[::2])\n",
    "ax.set_ylim([50000,250000]);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "690509e9",
   "metadata": {},
   "source": [
    "## Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8afad86",
   "metadata": {},
   "source": [
    "### Conceptual"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9de5c05a",
   "metadata": {},
   "source": [
    "#### 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87af2f42",
   "metadata": {},
   "source": [
    "(a) Best subset selection has the smallest training RSS bacause it searchs for all possible combinations that has exactly $k$ predictors, while forward and backward stepwise selection don't. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a039c1b3",
   "metadata": {},
   "source": [
    "(b) We cannot state for sure which of thre three models with $k$ predictors will have the smallest test RSS;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22540bc1",
   "metadata": {},
   "source": [
    "(c) \n",
    "- i. True;\n",
    "- ii. True;\n",
    "- iii. False;\n",
    "- iv. False;\n",
    "- v. False; "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "042597c7",
   "metadata": {},
   "source": [
    "#### 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "265f8c2d",
   "metadata": {},
   "source": [
    "(a)False; False; True; False;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad855150",
   "metadata": {},
   "source": [
    "(b)False; False; True; False;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c05ff585",
   "metadata": {},
   "source": [
    "(c) False; True; False; False;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d56e69e7",
   "metadata": {},
   "source": [
    "### Applied"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac42410b",
   "metadata": {},
   "source": [
    "#### 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8073343",
   "metadata": {},
   "outputs": [],
   "source": [
    "# a)\n",
    "\n",
    "# Random predictors and noise.\n",
    "X: np.ndarray = np.random.normal(loc=0.0, scale=1.0, size=(100, 1))\n",
    "eps: np.ndarray = np.random.normal(loc=0.0, scale=1.0, size=(100, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "474263a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# b)\n",
    "\n",
    "# Real parameters that generate data.\n",
    "B0: float = 5\n",
    "B1: float = -10\n",
    "B2: float = 3\n",
    "B3: float = 14\n",
    "\n",
    "# Response.\n",
    "Y: np.ndarray = B0 + B1 * X + B2 * (X ** 2) + B3 * (X ** 3) + eps\n",
    "\n",
    "# To dataframes.\n",
    "dfY: pd.DataFrame = pd.DataFrame(Y, columns=[\"Y\"])\n",
    "dfY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4088fe83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# c)\n",
    "\n",
    "# As dataframe with intercept.\n",
    "Features: np.ndarray = np.hstack([X ** i for i in range(0, 11)])\n",
    "dfX = pd.DataFrame(Features, columns=[f\"X{i}\" for i in range(0, 11)])\n",
    "dfX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12ca090c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adjust a linear model with all predictors.\n",
    "linear_model = OLS(endog=dfY, exog=dfX).fit()\n",
    "linear_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10640057",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For model selection criterion scorer.\n",
    "sigma2 = linear_model.scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69ee8ee8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run forward stepwise selection.\n",
    "n_features, rss_list, r2_list, bic_list, aic_list, cp_list, best_models = aux.forward_stepwise_selection(dfX, df, sigma2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7ddc93c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make figures.\n",
    "fig, axs = subplots(5, 1, figsize=(6, 8), sharex=True)\n",
    "\n",
    "# Plot metrics.\n",
    "axs[0].plot(n_features, rss_list, marker=\"o\")\n",
    "axs[0].set_ylabel(\"RSS\")\n",
    "axs[1].plot(n_features, r2_list, marker=\"o\")\n",
    "axs[1].set_ylabel(\"R2\")\n",
    "axs[2].plot(n_features, cp_list, marker=\"o\")\n",
    "axs[2].set_ylabel(\"Cp\")\n",
    "axs[3].plot(n_features, bic_list, marker=\"o\")\n",
    "axs[3].set_ylabel(\"BIC\")\n",
    "axs[4].plot(n_features, aic_list, marker=\"o\")\n",
    "axs[4].set_ylabel(\"AIC\")\n",
    "axs[4].set_xlabel(\"Number of features\")\n",
    "\n",
    "# Plot minimum RSS as a red cross.\n",
    "min_rss_idx = np.argmin(rss_list)\n",
    "axs[0].plot(n_features[min_rss_idx], rss_list[min_rss_idx], marker=\"x\", color=\"red\", markersize=15)\n",
    "\n",
    "# Plot maximum R2 as a red cross.\n",
    "max_r2_idx = np.argmax(r2_list)\n",
    "axs[1].plot(n_features[max_r2_idx], r2_list[max_r2_idx], marker=\"x\", color=\"red\", markersize=15)\n",
    "\n",
    "# Plot maximum cp as a red cross.\n",
    "max_cp_idx = np.argmax(cp_list)\n",
    "axs[2].plot(n_features[max_cp_idx], cp_list[max_cp_idx], marker=\"x\", color=\"red\", markersize=15)\n",
    "\n",
    "# Plot minimum BIC as a red cross.\n",
    "min_bic_idx = np.argmin(bic_list)\n",
    "axs[3].plot(n_features[min_bic_idx], bic_list[min_bic_idx], marker=\"x\", color=\"red\", markersize=15)\n",
    "\n",
    "# Plot minimum AIC as a red cross.\n",
    "min_aic_idx = np.argmin(aic_list)\n",
    "axs[4].plot(n_features[min_aic_idx], aic_list[min_aic_idx], marker=\"x\", color=\"red\", markersize=15)\n",
    "\n",
    "# X labels.\n",
    "axs[4].set_xticks(n_features)\n",
    "\n",
    "# Set grid for all axes.\n",
    "for ax in axs:\n",
    "    ax.grid(alpha=0.15)\n",
    "\n",
    "# Title.\n",
    "axs[0].set_title(\"Forward Stepwise Selection Metrics\", fontsize=16)\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79b87873",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Expected coefficients.\n",
    "df_compare_forward: pd.DataFrame = pd.DataFrame({\n",
    "    \"true\": [B0, B1, B2, B3] + [0.0]*7\n",
    "}, index=[f\"X{i}\" for i in range(0, 11)])\n",
    "\n",
    "# Adjusted coefficients of the best model according to Cp, BIC, AIC, and R2.\n",
    "df_cp: pd.DataFrame = best_models[max_cp_idx].params.to_frame(name=\"forward_cp\")\n",
    "df_bic: pd.DataFrame = best_models[min_bic_idx].params.to_frame(name=\"forward_bic\")\n",
    "df_aic: pd.DataFrame = best_models[min_aic_idx].params.to_frame(name=\"forward_aic\")\n",
    "df_r2: pd.DataFrame = best_models[max_r2_idx].params.to_frame(name=\"forward_r2\")\n",
    "\n",
    "# Join all dataframes.\n",
    "df_compare_forward = df_compare_forward.join(df_cp, how=\"outer\")\n",
    "df_compare_forward = df_compare_forward.join(df_bic, how=\"outer\")\n",
    "df_compare_forward = df_compare_forward.join(df_aic, how=\"outer\")  \n",
    "df_compare_forward = df_compare_forward.join(df_r2, how=\"outer\")\n",
    "\n",
    "# Reduce float precision.\n",
    "df_compare_forward = df_compare_forward.round(3)\n",
    "\n",
    "# Better sorting of the index.\n",
    "df_compare_forward = df_compare_forward.reindex(natsorted(df_compare_forward.index))\n",
    "\n",
    "df_compare_forward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "356b40b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# c)\n",
    "\n",
    "# Run backward stepwise selection.\n",
    "n_features, rss_list, r2_list, bic_list, aic_list, cp_list, best_models = backward_stepwise_selection(dfX, dfY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8103963d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make figures.\n",
    "fig, axs = subplots(5, 1, figsize=(6, 8), sharex=True)\n",
    "\n",
    "# Plot metrics.\n",
    "axs[0].plot(n_features, rss_list, marker=\"o\")\n",
    "axs[0].set_ylabel(\"RSS\")\n",
    "axs[1].plot(n_features, r2_list, marker=\"o\")\n",
    "axs[1].set_ylabel(\"R2\")\n",
    "axs[2].plot(n_features, cp_list, marker=\"o\")\n",
    "axs[2].set_ylabel(\"Cp\")\n",
    "axs[3].plot(n_features, bic_list, marker=\"o\")\n",
    "axs[3].set_ylabel(\"BIC\")\n",
    "axs[4].plot(n_features, aic_list, marker=\"o\")\n",
    "axs[4].set_ylabel(\"AIC\")\n",
    "axs[4].set_xlabel(\"Number of features\")\n",
    "\n",
    "# Plot minimum RSS as a red cross.\n",
    "min_rss_idx = np.argmin(rss_list)\n",
    "axs[0].plot(n_features[min_rss_idx], rss_list[min_rss_idx], marker=\"x\", color=\"red\", markersize=15)\n",
    "\n",
    "# Plot maximum R2 as a red cross.\n",
    "max_r2_idx = np.argmax(r2_list)\n",
    "axs[1].plot(n_features[max_r2_idx], r2_list[max_r2_idx], marker=\"x\", color=\"red\", markersize=15)\n",
    "\n",
    "# Plot maximum cp as a red cross.\n",
    "max_cp_idx = np.argmax(cp_list)\n",
    "axs[2].plot(n_features[max_cp_idx], cp_list[max_cp_idx], marker=\"x\", color=\"red\", markersize=15)\n",
    "\n",
    "# Plot minimum BIC as a red cross.\n",
    "min_bic_idx = np.argmin(bic_list)\n",
    "axs[3].plot(n_features[min_bic_idx], bic_list[min_bic_idx], marker=\"x\", color=\"red\", markersize=15)\n",
    "\n",
    "# Plot minimum AIC as a red cross.\n",
    "min_aic_idx = np.argmin(aic_list)\n",
    "axs[4].plot(n_features[min_aic_idx], aic_list[min_aic_idx], marker=\"x\", color=\"red\", markersize=15)\n",
    "\n",
    "# X labels.\n",
    "axs[4].set_xticks(n_features)\n",
    "\n",
    "# Set grid for all axes.\n",
    "for ax in axs:\n",
    "    ax.grid(alpha=0.15)\n",
    "\n",
    "# Title.\n",
    "axs[0].set_title(\"Backward Stepwise Selection Metrics\", fontsize=16)\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4be00b47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize.\n",
    "df_compare_backward: pd.DataFrame = pd.DataFrame({\n",
    "    \"true\": [B0, B1, B2, B3] + [0.0]*7\n",
    "}, index=[f\"X{i}\" for i in range(0, 11)])\n",
    "\n",
    "# Adjusted coefficients of the best model according to Cp, BIC, AIC, and R2.\n",
    "df_cp: pd.DataFrame = best_models[max_cp_idx].params.to_frame(name=\"backward_cp\")\n",
    "df_bic: pd.DataFrame = best_models[min_bic_idx].params.to_frame(name=\"backward_bic\")\n",
    "df_aic: pd.DataFrame = best_models[min_aic_idx].params.to_frame(name=\"backward_aic\")\n",
    "df_r2: pd.DataFrame = best_models[max_r2_idx].params.to_frame(name=\"backward_r2\")\n",
    "\n",
    "# Join all dataframes.\n",
    "df_compare_backward = df_compare_backward.join(df_cp, how=\"outer\")\n",
    "df_compare_backward = df_compare_backward.join(df_bic, how=\"outer\")\n",
    "df_compare_backward = df_compare_backward.join(df_aic, how=\"outer\")  \n",
    "df_compare_backward = df_compare_backward.join(df_r2, how=\"outer\")\n",
    "\n",
    "# Reduce float precision.\n",
    "df_compare_backward = df_compare_backward.round(3)\n",
    "\n",
    "# Better sorting of the index.\n",
    "df_compare_backward = df_compare_backward.reindex(natsorted(df_compare_backward.index))\n",
    "\n",
    "# Show it.\n",
    "df_compare_backward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34982e25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Join results dataframes.\n",
    "df_results: pd.DataFrame = pd.concat([\n",
    "        df_compare_forward, \n",
    "        df_compare_backward.drop(columns=[\"true\"])\n",
    "    ], \n",
    "    axis=1\n",
    ").T\n",
    "\n",
    "# Show it.\n",
    "df_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbbcfc09",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# e)\n",
    "\n",
    "# Exclude constant term.\n",
    "X: np.array = np.asarray(dfX.drop(columns=[\"X0\"]))\n",
    "y: np.array = dfY[\"Y\"].values\n",
    "\n",
    "# Hyperparameters.\n",
    "lambdas: np.array = 10 ** np.linspace(6, -5, 100) / y.std() \n",
    "K: int = 10\n",
    "kfold = skm.KFold(K, random_state=0, shuffle=True)\n",
    "\n",
    "# Lasso with cross-validation.\n",
    "lassocv = skl.ElasticNetCV(l1_ratio=1.0, alphas=lambdas, cv=kfold)\n",
    "scaler = StandardScaler(with_mean=True, with_std=True)\n",
    "pipelinecv = Pipeline(steps=[(\"scaler\", scaler), (\"lassocv\", lassocv)])\n",
    "\n",
    "# Fit the models.\n",
    "pipelinecv.fit(X, y)\n",
    "\n",
    "# Show results.\n",
    "tunned_lasso = pipelinecv.named_steps[\"lassocv\"]\n",
    "tunned_lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ae5003e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mean and error of the MSE path.\n",
    "cv_mse: np.array = tunned_lasso.mse_path_.mean(axis=1)\n",
    "cv_mse_err: np.array = tunned_lasso.mse_path_.std(1) / np.sqrt(K)\n",
    "\n",
    "# Find better results.\n",
    "best_idx: int = np.argmin(cv_mse)\n",
    "\n",
    "print(f\">>> Best lambda: {lambdas[best_idx]:.5e}\")\n",
    "print(f\">>> Best CV MSE: {cv_mse[best_idx]:.4f} +/- {cv_mse_err[best_idx]:.4f}\")\n",
    "\n",
    "# Create figure.\n",
    "path_fig, ax = subplots(figsize=(9, 4.5)) \n",
    "\n",
    "# Plot it.\n",
    "ax.errorbar(\n",
    "    lambdas, \n",
    "    cv_mse, \n",
    "    yerr=cv_mse_err,\n",
    "    marker=\".\"\n",
    ")\n",
    "\n",
    "# Plot better lambda as a red cross.\n",
    "ax.plot(\n",
    "    lambdas[best_idx],\n",
    "    cv_mse[best_idx],\n",
    "    marker=\"x\",\n",
    "    color=\"red\",\n",
    "    markersize=10,\n",
    "    markeredgewidth=2\n",
    ")\n",
    "\n",
    "# Labels.\n",
    "ax.set_xscale(\"log\")\n",
    "ax.set_yscale(\"log\")\n",
    "ax.set_xlabel(\"$\\\\lambda$\")\n",
    "ax.set_ylabel(\"Mean Squared Error (MSE)\")\n",
    "ax.set_title(\"Lasso: Cross-validated MSE\", weight=\"bold\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd9cd772",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lasso results.\n",
    "new_row = pd.DataFrame(\n",
    "    np.hstack([tunned_lasso.intercept_, tunned_lasso.coef_])[None, :], \n",
    "    columns=dfX.columns, \n",
    "    index=[\"lasso_cv\"]\n",
    ")\n",
    "\n",
    "# Add lasso results to the results dataframe.\n",
    "df_results = pd.concat([df_results, new_row], axis=0)\n",
    "\n",
    "# Show it.\n",
    "df_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53a5d789",
   "metadata": {},
   "outputs": [],
   "source": [
    "# f)\n",
    "\n",
    "# Random predictors and noise.\n",
    "X: np.ndarray = np.random.normal(loc=0.0, scale=1.0, size=(100, 1))\n",
    "eps: np.ndarray = np.random.normal(loc=0.0, scale=1.0, size=(100, 1))\n",
    "\n",
    "# Real parameters that generate data.\n",
    "B0: float = 10\n",
    "B7: float = 2.0\n",
    "\n",
    "# Response.\n",
    "Y: np.ndarray = B0 + B7 * (X ** 7) + eps\n",
    "\n",
    "# To dataframes.\n",
    "dfY: pd.DataFrame = pd.DataFrame(Y, columns=[\"Y\"])\n",
    "\n",
    "# As dataframe with intercept.\n",
    "Features: np.ndarray = np.hstack([X ** i for i in range(0, 11)])\n",
    "dfX = pd.DataFrame(Features, columns=[f\"X{i}\" for i in range(0, 11)])\n",
    "dfX\n",
    "\n",
    "# Adjust a linear model with all predictors.\n",
    "linear_model = OLS(endog=dfY, exog=dfX).fit()\n",
    "\n",
    "# Model selection criterion scorer.\n",
    "sigma2 = linear_model.scale\n",
    "neg_Cp = partial(nCp , sigma2)\n",
    "\n",
    "# Run forward stepwise selection.\n",
    "n_features, rss_list, r2_list, bic_list, aic_list, cp_list, best_models = forward_stepwise_selection(dfX, dfY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b4e2027",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make figures.\n",
    "fig, axs = subplots(5, 1, figsize=(6, 8), sharex=True)\n",
    "\n",
    "# Plot metrics.\n",
    "axs[0].plot(n_features, rss_list, marker=\"o\")\n",
    "axs[0].set_ylabel(\"RSS\")\n",
    "axs[1].plot(n_features, r2_list, marker=\"o\")\n",
    "axs[1].set_ylabel(\"R2\")\n",
    "axs[2].plot(n_features, cp_list, marker=\"o\")\n",
    "axs[2].set_ylabel(\"Cp\")\n",
    "axs[3].plot(n_features, bic_list, marker=\"o\")\n",
    "axs[3].set_ylabel(\"BIC\")\n",
    "axs[4].plot(n_features, aic_list, marker=\"o\")\n",
    "axs[4].set_ylabel(\"AIC\")\n",
    "axs[4].set_xlabel(\"Number of features\")\n",
    "\n",
    "# Plot minimum RSS as a red cross.\n",
    "min_rss_idx = np.argmin(rss_list)\n",
    "axs[0].plot(n_features[min_rss_idx], rss_list[min_rss_idx], marker=\"x\", color=\"red\", markersize=15)\n",
    "\n",
    "# Plot maximum R2 as a red cross.\n",
    "max_r2_idx = np.argmax(r2_list)\n",
    "axs[1].plot(n_features[max_r2_idx], r2_list[max_r2_idx], marker=\"x\", color=\"red\", markersize=15)\n",
    "\n",
    "# Plot maximum cp as a red cross.\n",
    "max_cp_idx = np.argmax(cp_list)\n",
    "axs[2].plot(n_features[max_cp_idx], cp_list[max_cp_idx], marker=\"x\", color=\"red\", markersize=15)\n",
    "\n",
    "# Plot minimum BIC as a red cross.\n",
    "min_bic_idx = np.argmin(bic_list)\n",
    "axs[3].plot(n_features[min_bic_idx], bic_list[min_bic_idx], marker=\"x\", color=\"red\", markersize=15)\n",
    "\n",
    "# Plot minimum AIC as a red cross.\n",
    "min_aic_idx = np.argmin(aic_list)\n",
    "axs[4].plot(n_features[min_aic_idx], aic_list[min_aic_idx], marker=\"x\", color=\"red\", markersize=15)\n",
    "\n",
    "# X labels.\n",
    "axs[4].set_xticks(n_features)\n",
    "\n",
    "# Set grid for all axes.\n",
    "for ax in axs:\n",
    "    ax.grid(alpha=0.15)\n",
    "\n",
    "# Title.\n",
    "axs[0].set_title(\"Forward Stepwise Selection Metrics\", fontsize=16)\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9733f001",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# Exclude constant term.\n",
    "X: np.array = np.asarray(dfX.drop(columns=[\"X0\"]))\n",
    "y: np.array = dfY[\"Y\"].values\n",
    "\n",
    "# Hyperparameters.\n",
    "lambdas: np.array = 10 ** np.linspace(10, -12, 200) / y.std() \n",
    "K: int = 10\n",
    "kfold = skm.KFold(K, random_state=0, shuffle=True)\n",
    "\n",
    "# Lasso with cross-validation.\n",
    "lassocv = skl.ElasticNetCV(l1_ratio=1.0, alphas=lambdas, cv=kfold)\n",
    "scaler = StandardScaler()\n",
    "pipelinecv = Pipeline(steps=[(\"scaler\", scaler), (\"lassocv\", lassocv)])\n",
    "\n",
    "# Fit the models.\n",
    "pipelinecv.fit(X, y)\n",
    "\n",
    "# Show results.\n",
    "tunned_lasso = pipelinecv.named_steps[\"lassocv\"]\n",
    "tunned_lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04c48a08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mean and error of the MSE path.\n",
    "cv_mse: np.array = tunned_lasso.mse_path_.mean(axis=1)\n",
    "cv_mse_err: np.array = tunned_lasso.mse_path_.std(1) / np.sqrt(K)\n",
    "\n",
    "# Find better results.\n",
    "best_idx: int = np.argmin(cv_mse)\n",
    "\n",
    "print(f\">>> Best lambda: {lambdas[best_idx]:.5e}\")\n",
    "print(f\">>> Best CV MSE: {cv_mse[best_idx]:.4f} +/- {cv_mse_err[best_idx]:.4f}\")\n",
    "\n",
    "# Create figure.\n",
    "path_fig, ax = subplots(figsize=(9, 4.5)) \n",
    "\n",
    "# Plot it.\n",
    "ax.errorbar(\n",
    "    lambdas, \n",
    "    cv_mse, \n",
    "    yerr=cv_mse_err,\n",
    "    marker=\".\"\n",
    ")\n",
    "\n",
    "# Plot better lambda as a red cross.\n",
    "ax.plot(\n",
    "    lambdas[best_idx],\n",
    "    cv_mse[best_idx],\n",
    "    marker=\"x\",\n",
    "    color=\"red\",\n",
    "    markersize=10,\n",
    "    markeredgewidth=2\n",
    ")\n",
    "\n",
    "# Labels.\n",
    "ax.set_xscale(\"log\")\n",
    "ax.set_yscale(\"log\")\n",
    "ax.set_xlabel(\"$\\\\lambda$\")\n",
    "ax.set_ylabel(\"Mean Squared Error (MSE)\")\n",
    "ax.set_title(\"Lasso: Cross-validated MSE\", weight=\"bold\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb2eef3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Expected coefficients.\n",
    "df_compare_forward: pd.DataFrame = pd.DataFrame({\n",
    "    \"true\": [B0, 0, 0, 0, 0, 0, 0, B7, 0, 0, 0]\n",
    "}, index=[f\"X{i}\" for i in range(0, 11)])\n",
    "\n",
    "# Adjusted coefficients of the best model according to Cp, BIC, AIC, and R2.\n",
    "df_cp: pd.DataFrame = best_models[max_cp_idx].params.to_frame(name=\"forward_cp\")\n",
    "df_bic: pd.DataFrame = best_models[min_bic_idx].params.to_frame(name=\"forward_bic\")\n",
    "df_aic: pd.DataFrame = best_models[min_aic_idx].params.to_frame(name=\"forward_aic\")\n",
    "df_r2: pd.DataFrame = best_models[max_r2_idx].params.to_frame(name=\"forward_r2\")\n",
    "\n",
    "# Join all dataframes.\n",
    "df_compare_forward = df_compare_forward.join(df_cp, how=\"outer\")\n",
    "df_compare_forward = df_compare_forward.join(df_bic, how=\"outer\")\n",
    "df_compare_forward = df_compare_forward.join(df_aic, how=\"outer\")  \n",
    "df_compare_forward = df_compare_forward.join(df_r2, how=\"outer\")\n",
    "\n",
    "# Reduce float precision.\n",
    "df_compare_forward = df_compare_forward.round(3)\n",
    "\n",
    "# Better sorting of the index.\n",
    "df_compare_forward = df_compare_forward.reindex(natsorted(df_compare_forward.index))\n",
    "\n",
    "# Traspose it.\n",
    "df_results = df_compare_forward.T\n",
    "\n",
    "# Lasso results.\n",
    "new_row = pd.DataFrame(\n",
    "    np.hstack([tunned_lasso.intercept_, tunned_lasso.coef_])[None, :], \n",
    "    columns=dfX.columns, \n",
    "    index=[\"lasso_cv\"]\n",
    ")\n",
    "\n",
    "# Add lasso results to the results dataframe.\n",
    "df_results = pd.concat([df_results, new_row], axis=0)\n",
    "\n",
    "# Show it.\n",
    "df_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be14a705",
   "metadata": {},
   "source": [
    "#### 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "754ef5c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load into memory.\n",
    "college_df: pd.DataFrame = pd.read_csv(\"/statapp/islp/data/College.csv\")\n",
    "\n",
    "# Show it.\n",
    "college_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "716e20f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Histogram target variable.\n",
    "fig, ax = subplots(figsize=(8, 4))\n",
    "college_df[\"Apps\"].hist(bins=50, ax=ax)\n",
    "ax.set_xlabel(\"Number of applications received\")\n",
    "ax.set_ylabel(\"Frequency\")\n",
    "\n",
    "# Mean and standard deviation.\n",
    "print(f\">>> Mean: {college_df['Apps'].mean():.2f}\")\n",
    "print(f\">>> Median: {college_df['Apps'].median():.2f}\")\n",
    "print(f\">>> Standard deviation: {college_df['Apps'].std():.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54d885d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# (a)\n",
    "\n",
    "# Features. Drop categorial and identifier columns\n",
    "dfX: pd.DataFrame = college_df.drop(\n",
    "    columns=[\"Unnamed: 0\", \"Private\", \"Apps\",]\n",
    ")\n",
    "\n",
    "# Add a first column of ones for the intercept.\n",
    "dfX.insert(0, \"Intercept\", 1.0)\n",
    "\n",
    "# Target\n",
    "sy: pd.Series = college_df[\"Apps\"]\n",
    "\n",
    "# Data split.\n",
    "dfX_train, dfX_test, sy_train, sy_test = train_test_split(dfX, sy, train_size=0.75, random_state=56)\n",
    "\n",
    "print(f\">>> Training set shape: {dfX_train.shape}\")\n",
    "print(f\">>> Test set shape: {dfX_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce3232d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# b) \n",
    "\n",
    "# Fit a linear model using least squares with all predictors\n",
    "linear_model = OLS(endog=sy_train, exog=dfX_train).fit()\n",
    "\n",
    "# Predictions in training sample\n",
    "sy_train_hat = linear_model.predict(dfX_train)\n",
    "\n",
    "# Predictions in test sample\n",
    "sy_test_hat = linear_model.predict(dfX_test)\n",
    "\n",
    "# Calculate mean squared error\n",
    "mse_train: float = ((sy_train_hat - sy_train) ** 2).mean()\n",
    "mse_test: float = ((sy_test_hat - sy_test) ** 2).mean()\n",
    "\n",
    "# Show it\n",
    "print(f\">>> Training MSE: {mse_train:.2e}\")\n",
    "print(f\">>> Test MSE: {mse_test:.2e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3869729",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# c)\n",
    "\n",
    "# Training data as numpy arrays. Ignore first column (intercept)\n",
    "X_train: np.ndarray = dfX_train.iloc[:, 1:].values\n",
    "y_train: np.ndarray = sy_train.values\n",
    "\n",
    "# Test data as numpy arrays\n",
    "X_test: np.ndarray = dfX_test.iloc[:, 1:].values\n",
    "y_test: np.ndarray = sy_test.values\n",
    "\n",
    "# Define lambdas based on complete training target standard deviation\n",
    "lambdas: np.ndarray = 10 ** np.linspace(11, -3, 100) / y_train.std() \n",
    "\n",
    "print(f\">>> Number of lambdas: {lambdas.shape[0]}\")\n",
    "print(f\">>> Lambda max: {lambdas.max():.2e}\")\n",
    "print(f\">>> Lambda min: {lambdas.min():.2e}\\n\")\n",
    "\n",
    "# The pipeline first scales the features and then applies Ridge regression\n",
    "pipeline = Pipeline([(\"scaler\", StandardScaler()),(\"ridge_regression\", Ridge())])\n",
    "\n",
    "# Alpha is the parameter for the Ridge model\n",
    "param_grid: Dict[str, np.ndarray] = {\"ridge_regression__alpha\": lambdas}\n",
    "\n",
    "# GridSearchCV will perform an exhaustive search over the defined alpha values\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=pipeline,\n",
    "    param_grid=param_grid,\n",
    "    cv=5, \n",
    "    scoring='neg_mean_squared_error', # or 'r2'\n",
    "    verbose=1,\n",
    "    n_jobs=-1 # Use all available cores\n",
    ")\n",
    "\n",
    "# This step runs the cross-validation for all alpha values within the pipeline\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the best model on the test set using MSE\n",
    "best_model_ridge = grid_search.best_estimator_\n",
    "y_test_pred: np.ndarray = best_model_ridge.predict(X_test)\n",
    "test_mse: float = mean_squared_error(y_test, y_test_pred)\n",
    "\n",
    "# Retrieve the best alpha and model score\n",
    "print(f\">>> Best alpha found by `GridSearchCV`: {grid_search.best_params_['ridge_regression__alpha']:.2e}\")\n",
    "print(f\">>> Best cross-validation score MSE: {(-1.0) * grid_search.best_score_:.2e}\")\n",
    "print(f\">>> Test set MSE of the best model: {test_mse:.2e}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e4d19fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create figure\n",
    "path_fig, ax = subplots(figsize=(9, 4.5)) \n",
    "\n",
    "# Plot it\n",
    "ax.errorbar(\n",
    "    grid_search.cv_results_[\"param_ridge_regression__alpha\"].data, \n",
    "    (-1.0) * grid_search.cv_results_[\"mean_test_score\"], \n",
    "    yerr=grid_search.cv_results_[\"std_test_score\"],\n",
    "    marker=\".\",\n",
    "    label=\"Cross-validated MSE (Training Set)\"\n",
    ")\n",
    "\n",
    "# Plot better lambda as a red cross\n",
    "ax.plot(\n",
    "    grid_search.best_params_['ridge_regression__alpha'],\n",
    "    (-1.0) * grid_search.best_score_,\n",
    "    marker=\"x\",\n",
    "    color=\"red\",\n",
    "    markersize=10,\n",
    "    markeredgewidth=2\n",
    ")\n",
    "\n",
    "# Plot Linear Regression MSE as a horizontal green dashed line\n",
    "ax.axhline(y=mse_test, color=\"green\", linestyle=\"--\", label=\"Linear Regression MSE on Test Set\")\n",
    "\n",
    "# Plot Ridge Regression MSE on Test Set as a horizontal orange dashed line\n",
    "ax.axhline(y=test_mse, color=\"orange\", linestyle=\"--\", label=\"Ridge Regression MSE on Test Set\")\n",
    "\n",
    "# Labels\n",
    "ax.legend()\n",
    "ax.set_xscale(\"log\")\n",
    "ax.set_yscale(\"log\")\n",
    "ax.set_xlabel(\"$\\\\lambda$\")\n",
    "ax.set_ylabel(\"Mean Squared Error (MSE)\")\n",
    "ax.set_title(\"Ridge Regression\\nCross-validated MSE\", weight=\"bold\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2abd528a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# d)\n",
    "\n",
    "# The pipeline ensures scaling happens inside the cross-validation loops\n",
    "lasso_pipeline = Pipeline([\n",
    "    (\"scaler\", StandardScaler()),\n",
    "    (\"lasso_cv\", LassoCV(cv=5, random_state=0, alphas=lambdas)) \n",
    "])\n",
    "\n",
    "# The fit method performs the cross-validation to find the optimal alpha\n",
    "lasso_pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the best model on the test set using MSE\n",
    "y_test_pred_lasso: np.ndarray = lasso_pipeline.predict(X_test)\n",
    "test_mse_lasso: float = mean_squared_error(y_test, y_test_pred_lasso)\n",
    "\n",
    "# Retrieve the best alpha and model score\n",
    "best_model_lasso = lasso_pipeline.named_steps[\"lasso_cv\"]\n",
    "print(f\">>> Best alpha found by `LassoCV`: {best_model_lasso.alpha_:.2e}\")\n",
    "print(f\">>> Best cross-validation score MSE: {best_model_lasso.mse_path_.mean(axis=1).min():.2e}\")\n",
    "print(f\">>> Test set MSE of the best model: {test_mse:.2e}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94262d74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create figure\n",
    "path_fig, ax = subplots(figsize=(9, 4.5)) \n",
    "\n",
    "# Plot it\n",
    "ax.errorbar(\n",
    "    lasso_pipeline.named_steps['lasso_cv'].alphas, \n",
    "    lasso_pipeline.named_steps['lasso_cv'].mse_path_.mean(axis=1), \n",
    "    yerr=lasso_pipeline.named_steps['lasso_cv'].mse_path_.std(axis=1),\n",
    "    marker=\".\",\n",
    "    label=\"Cross-validated MSE (Training Set)\"\n",
    ")\n",
    "\n",
    "# Plot better lambda as a red cross\n",
    "ax.plot(\n",
    "    best_model_lasso.alpha_,\n",
    "    best_model_lasso.mse_path_.mean(axis=1).min(),\n",
    "    marker=\"x\",\n",
    "    color=\"red\",\n",
    "    markersize=10,\n",
    "    markeredgewidth=2\n",
    ")\n",
    "\n",
    "# Plot Linear Regression MSE as a horizontal green dashed line\n",
    "ax.axhline(y=mse_test, color=\"green\", linestyle=\"--\", label=\"Linear Regression MSE on Test Set\")\n",
    "\n",
    "# Plot Lasso MSE on Test Set as a horizontal orange dashed line\n",
    "ax.axhline(y=test_mse_lasso, color=\"orange\", linestyle=\"--\", label=\"Lasso Regression MSE on Test Set\")\n",
    "\n",
    "# Labels\n",
    "ax.legend()\n",
    "ax.set_xscale(\"log\")\n",
    "ax.set_yscale(\"log\")\n",
    "ax.set_xlabel(\"$\\\\lambda$\")\n",
    "ax.set_ylabel(\"Mean Squared Error (MSE)\")\n",
    "ax.set_title(\"Lasso Regression\\nCross-validated MSE\", weight=\"bold\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73b7d63a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "728f173a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0758b47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Columns for coefficients DataFrame\n",
    "columns: List[str] = dfX_train.columns.to_list()\n",
    "\n",
    "# Grab coefficients of least squares model\n",
    "ols_coefs: np.ndarray = linear_model.params.values[None, :]\n",
    "\n",
    "# Grab coefficients of best Ridge model. Scale parameters back to original data scale\n",
    "scaler = best_model_ridge.named_steps[\"scaler\"]\n",
    "mu = scaler.mean_\n",
    "sigma = np.sqrt(scaler.var_)\n",
    "ridge_coefs: np.ndarray = best_model_ridge.named_steps[\"ridge_regression\"].coef_ / sigma\n",
    "ridge_intercept: float = best_model_ridge.named_steps[\"ridge_regression\"].intercept_ - np.sum((mu / sigma) * best_model_ridge.named_steps[\"ridge_regression\"].coef_)\n",
    "\n",
    "# Grab coefficients of best Lasso model in original data scale\n",
    "scaler = lasso_pipeline.named_steps[\"scaler\"]\n",
    "mu = scaler.mean_\n",
    "sigma = np.sqrt(scaler.var_)\n",
    "lasso_coefs: np.ndarray = best_model_lasso.coef_ / sigma\n",
    "lasso_intercept: float = best_model_lasso.intercept_ - np.sum((mu / sigma) * best_model_lasso.coef_)\n",
    "\n",
    "# Create a DataFrame to compare coefficients\n",
    "df_coefs: pd.DataFrame = pd.DataFrame(\n",
    "    ols_coefs, \n",
    "    columns=columns, \n",
    "    index=[\"least_squares\"]\n",
    ")\n",
    "\n",
    "# Add Ridge coefficients\n",
    "df_coefs = pd.concat([\n",
    "    df_coefs,\n",
    "    pd.DataFrame(\n",
    "        np.hstack([ridge_intercept, ridge_coefs])[None, :], \n",
    "        columns=columns, \n",
    "        index=[\"ridge_cv\"]\n",
    "    )\n",
    "], axis=0)\n",
    "\n",
    "# Add Lasso coefficients\n",
    "df_coefs = pd.concat([\n",
    "    df_coefs,\n",
    "    pd.DataFrame(\n",
    "        np.hstack([lasso_intercept, lasso_coefs])[None, :], \n",
    "        columns=columns, \n",
    "        index=[\"lasso_cv\"]\n",
    "    )\n",
    "], axis=0)\n",
    "\n",
    "\n",
    "# Show it\n",
    "df_coefs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e32689c9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f6c59ec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af01d631",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
